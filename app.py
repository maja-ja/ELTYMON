import streamlit as st
import pandas as pd
import base64
import time
import json
import re  # æ–°å¢ï¼šç”¨æ–¼ç²¾æº–æå– JSON
from io import BytesIO
from gtts import gTTS
import google.generativeai as genai
from streamlit_gsheets import GSheetsConnection

# ==========================================
# 1. æ ¸å¿ƒé…ç½®èˆ‡è¦–è¦ºç¾åŒ– (CSS)
# ==========================================
st.set_page_config(page_title="Etymon Decoder v2.5", page_icon="ğŸ§©", layout="wide")
def inject_custom_css():
    st.markdown("""
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Noto+Sans+TC:wght@500;700&display=swap');
            
            /* 1. æ‹†è§£å€å¡Šæ¨£å¼ */
            .breakdown-container {
                font-family: 'Inter', 'Noto Sans TC', sans-serif; 
                font-size: 1.8rem !important; 
                font-weight: 700;
                letter-spacing: 1px;
                background: linear-gradient(135deg, #1E88E5 0%, #1565C0 100%);
                color: #FFFFFF;
                padding: 12px 30px;
                border-radius: 15px;
                display: inline-block;
                margin: 20px 0;
                box-shadow: 0 4px 15px rgba(30, 136, 229, 0.3);
                border: 1px solid rgba(255, 255, 255, 0.2);
            }
            .breakdown-container span.operator {
                color: #BBDEFB;
                margin: 0 8px;
            }

            /* 2. æ‰‹æ©ŸéŸ¿æ‡‰å¼èª¿æ•´ */
            @media (max-width: 600px) {
                .breakdown-container {
                    font-size: 1.2rem !important;
                    display: block;
                    text-align: center;
                }
            }

            /* 3. å–®å­—èˆ‡éŸ³æ¨™ */
            .hero-word { font-size: 2.5rem; font-weight: 800; color: #333; }
            /* å¦‚æœåœ¨æ·±è‰²æ¨¡å¼ä¸‹ï¼Œå–®å­—æ¨™é¡Œä¹Ÿè¦ç¢ºä¿çœ‹å¾—åˆ° */
            @media (prefers-color-scheme: dark) {
                .hero-word { color: #FFF; }
            }
            .hero-phonetic { font-size: 1.2rem; color: #888; font-family: monospace; margin-bottom: 10px; }

            /* 4. [ä¿®æ­£é»] èªæ„Ÿå€å¡Šï¼šå¼·åˆ¶æ·±è‰²æ–‡å­— */
            .vibe-box { 
                background-color: #E3F2FD; 
                padding: 15px; 
                border-radius: 10px; 
                border-left: 5px solid #2196F3; 
                
                /* é€™è£¡å¼·åˆ¶æŒ‡å®šæ–‡å­—é¡è‰²ç‚ºæ·±ç°ï¼Œé¿å…è¢«æ·±è‰²æ¨¡å¼åç™½ */
                color: #333333 !important; 
            }
            /* ç¢ºä¿ box è£¡é¢çš„æ¨™é¡Œä¹Ÿæ˜¯æ·±è—è‰² */
            .vibe-box h4 {
                color: #1565C0 !important;
            }
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. å·¥å…·å‡½å¼
# ==========================================

def speak(text, key_suffix=""):
    try:
        if not text: return
        tts = gTTS(text=text, lang='en')
        fp = BytesIO()
        tts.write_to_fp(fp)
        audio_base64 = base64.b64encode(fp.getvalue()).decode()
        unique_id = f"audio_{int(time.time())}_{key_suffix}"
        # éš±è—æ’­æ”¾å™¨ï¼Œè‡ªå‹•æ’­æ”¾
        st.components.v1.html(f'<audio id="{unique_id}" autoplay="true" style="display:none;"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio><script>document.getElementById("{unique_id}").play();</script>', height=0)
    except Exception as e: st.error(f"èªéŸ³éŒ¯èª¤: {e}")

def get_spreadsheet_url():
    """å®‰å…¨åœ°ç²å–è©¦ç®—è¡¨ç¶²å€ï¼Œç›¸å®¹å…©ç¨® secrets æ ¼å¼"""
    try:
        # å„ªå…ˆå˜—è©¦ connections çµæ§‹
        return st.secrets["connections"]["gsheets"]["spreadsheet"]
    except:
        try:
            # å‚™ç”¨ï¼šç›´æ¥çµæ§‹
            return st.secrets["gsheets"]["spreadsheet"]
        except:
            st.error("æ‰¾ä¸åˆ° spreadsheet è¨­å®šï¼Œè«‹æª¢æŸ¥ secrets.toml")
            return ""

@st.cache_data(ttl=60)
def load_db():
    COL_NAMES = [
        'category', 'roots', 'meaning', 'word', 'breakdown', 
        'definition', 'phonetic', 'example', 'translation', 'native_vibe',
        'synonym_nuance', 'visual_prompt', 'social_status', 'emotional_tone', 'street_usage',
        'collocation', 'etymon_story', 'usage_warning', 'memory_hook', 'audio_tag'
    ]
    
    # ä½¿ç”¨ GSheetsConnection è®€å– (æ¯” pd.read_csv æ›´ç©©å®šä¸”èƒ½åˆ©ç”¨å¿«å–)
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        url = get_spreadsheet_url()
        df = conn.read(spreadsheet=url, ttl=60) # åŠ å…¥ TTL é¿å…é »ç¹è®€å–
        
        # å¼·åˆ¶å°é½Š 20 æ¬„
        for col in COL_NAMES:
            if col not in df.columns:
                df[col] = ""
        
        # åªä¿ç•™é€™ 20 å€‹æ¬„ä½ä¸¦å»é™¤éå–®å­—è¡Œ
        df = df[COL_NAMES].dropna(subset=['word']).fillna("").reset_index(drop=True)
        return df
    except Exception as e:
        # Fallback: å¦‚æœé€£ç·šå¤±æ•—ï¼Œå›å‚³ç©ºè¡¨ä»¥å… App å´©æ½°
        st.error(f"è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        return pd.DataFrame(columns=COL_NAMES)

# ==========================================
# 3. AI è§£ç¢¼æ ¸å¿ƒ (è‡ªç”¨è§£é–ç‰ˆ)
# ==========================================
def ai_decode_and_save(input_text):
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    
    # è¨­å®šç„¡é™åˆ¶çš„å®‰å…¨éæ¿¾
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    model = genai.GenerativeModel('gemini-2.5-flash', safety_settings=safety_settings)
    
    prompt = f"""
    Role: å…¨é ˜åŸŸçŸ¥è­˜è§£æ§‹å°ˆå®¶ (Polymath Decoder).
    Task: åˆ†æè¼¸å…¥å…§å®¹ã€Œ{input_text}ã€ï¼Œåˆ¤æ–·å…¶é ˜åŸŸï¼ˆèªè¨€å­¸ç¿’ã€æ­·å²ã€ç§‘å­¸ã€å•†æ¥­ã€ç¨‹å¼ç¢¼ç­‰ï¼‰ï¼Œä¸¦å°‡å…¶è§£æ§‹ç‚ºçµæ§‹åŒ–çŸ¥è­˜ã€‚

    ## è™•ç†é‚è¼¯ (Field Mapping Strategy):
    è«‹å°‡çŸ¥è­˜æ˜ å°„åˆ°ä»¥ä¸‹ 20 å€‹å›ºå®šæ¬„ä½ä¸­ (æ¬„ä½åç¨±é›–ç„¶æ˜¯è‹±æ–‡å–®å­—ç›¸é—œï¼Œä½†è«‹éˆæ´»å€Ÿä»£)ï¼š
    
    1. **category**: çŸ¥è­˜åˆ†é¡ (å¦‚: ç‰©ç†å­¸ã€å•†æ¥­æ¨¡å‹ã€Pythonèªæ³•)ã€‚
    2. **word**: æ ¸å¿ƒæ¦‚å¿µåç¨± (Title)ã€‚
    3. **roots**: æ ¸å¿ƒåŸç† / é—œéµå…¬å¼ / åº•å±¤é‚è¼¯ (The "Root" cause)ã€‚
    4. **meaning**: è©²æ¦‚å¿µçš„æ ¸å¿ƒåƒ¹å€¼æˆ–è§£æ±ºäº†ä»€éº¼å•é¡Œã€‚
    5. **breakdown**: çµæ§‹æ‹†è§£ / æ­¥é©Ÿæµç¨‹ / ç¨‹å¼ç¢¼ç‰‡æ®µã€‚
    6. **definition**: çµ¦åˆå­¸è€…çš„ã€Œä¸€å¥è©±è§£é‡‹ã€ (ELI5)ã€‚
    7. **phonetic**: (è‹¥éå–®å­—) è«‹å¡«å…¥é—œéµäººåæˆ–é—œéµæ™‚é–“é»ã€‚
    8. **example**: å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ / å ´æ™¯ã€‚
    9. **translation**: é¡æ¯”èªªæ˜ (ç”¨ç”Ÿæ´»ä¾‹å­æ¯”å–»)ã€‚
    10. **native_vibe**: å°ˆå®¶è¦–è§’ / å…§è¡Œäººçš„å¿ƒæ³• (Insider Insight)ã€‚
    11. **synonym_nuance**: æ˜“æ··æ·†æ¦‚å¿µæ¯”è¼ƒ / ç›¸ä¼¼ç†è«–è¾¨æã€‚
    12. **visual_prompt**: è¦–è¦ºåŒ–æƒ³åƒç•«é¢ (å¹«åŠ©è¨˜æ†¶çš„åœ–æ™¯)ã€‚
    13. **social_status**: é‡è¦æ€§è©•ç´š / åœ¨è©²é ˜åŸŸçš„åœ°ä½ã€‚
    14. **emotional_tone**: å­¸ç¿’è©²çŸ¥è­˜çš„æƒ…ç·’åŸºèª¿ (å¦‚: åš´è‚…ã€åç›´è¦ºã€å„ªé›…)ã€‚
    15. **street_usage**: (è‹¥éå–®å­—) è«‹å¡«å…¥ã€Œå¸¸è¦‹èª¤å€ã€æˆ–ã€Œå‘ã€ã€‚
    16. **collocation**: ç›¸é—œè¯çš„çŸ¥è­˜é» / å»¶ä¼¸é–±è®€é—œéµå­—ã€‚
    17. **etymon_story**: èµ·æºæ•…äº‹ / ç™¼æ˜èƒŒæ™¯ / æ­·å²è„ˆçµ¡ã€‚
    18. **usage_warning**: ä½¿ç”¨æ³¨æ„ / é™åˆ¶æ¢ä»¶ / é‚Šç•Œæƒ…æ³ã€‚
    19. **memory_hook**: é‡‘å¥è¨˜æ†¶æ³• / å£è¨£ã€‚
    20. **audio_tag**: (ç•™ç©ºæˆ–å¡«å…¥ hashtags)ã€‚

    ## è¼¸å‡ºè¦ç¯„ï¼š
    1. å¿…é ˆæ˜¯åš´æ ¼çš„ JSON æ ¼å¼ã€‚
    2. å…§å®¹ä»¥ç¹é«”ä¸­æ–‡ç‚ºä¸»ã€‚
    3. ä¸è«–è¼¸å…¥æ˜¯ä»€éº¼ï¼Œéƒ½å¿…é ˆå¡«æ»¿ä¸Šè¿° 20 å€‹æ¬„ä½ï¼Œæ²’æœ‰çš„è«‹å¡« "ç„¡"ã€‚
    """
    
    response = model.generate_content(prompt)
    return response.text

def show_encyclopedia_card(row):
    """ç¾åŒ–é¡¯ç¤ºå–®ä¸€å–®å­—çš„ç™¾ç§‘å¡ç‰‡"""
    st.markdown(f"<div class='hero-word'>{row['word']}</div>", unsafe_allow_html=True)
    st.markdown(f"<div class='hero-phonetic'>/{row['phonetic']}/</div>", unsafe_allow_html=True)
    
    col_a, col_b = st.columns([1, 4])
    with col_a:
        if st.button("ğŸ”Š æœ—è®€", key=f"spk_{row['word']}_{int(time.time())}", use_container_width=True):
            speak(row['word'], "card")
    with col_b:
        styled_breakdown = str(row['breakdown']).replace("+", "<span class='operator'>+</span>")
        st.markdown(f"<div class='breakdown-container'>{styled_breakdown}</div>", unsafe_allow_html=True)

    c1, c2 = st.columns(2)
    with c1:
        st.info(f"**ğŸ¯ å®šç¾©ï¼š**\n{row['definition']}")
        st.write(f"**ğŸ“ ä¾‹å¥ï¼š**\n{row['example']}")
        st.caption(f"ï¼ˆ{row['translation']}ï¼‰")
    with c2:
        st.success(f"**ğŸ’¡ å­—æ ¹ï¼š** {row['roots']}\n\n**æ„ç¾©ï¼š** {row['meaning']}")
        st.markdown(f"**ğŸª è¨˜æ†¶é‰¤å­ï¼š**\n{row['memory_hook']}")

    # èªæ„Ÿéƒ¨åˆ†
    if row['native_vibe']:
        st.markdown(f"""
            <div class='vibe-box'>
                <h4 style='color:#1E88E5; margin-top:0;'>ğŸŒŠ æ¯èªäººå£«èªæ„Ÿ (Native Vibe)</h4>
                <p style='font-size: 1.1rem;'>{row['native_vibe']}</p>
            </div>
        """, unsafe_allow_html=True)

    with st.expander("ğŸ“š æŸ¥çœ‹æ·±åº¦ç™¾ç§‘ (æ–‡åŒ–ã€ç¤¾æœƒã€è¡—é ­å¯¦æˆ°)"):
        t1, t2, t3 = st.tabs(["ğŸ›ï¸ å­—æºæ–‡åŒ–", "ğŸ‘” ç¤¾æœƒåœ°ä½", "ğŸ˜ è¡—é ­å¯¦æˆ°"])
        with t1:
            st.write(f"**ğŸ“œ å­—æºæ•…äº‹ï¼š** {row['etymon_story']}")
            st.write(f"**âš–ï¸ åŒç¾©è©è¾¨æï¼š** {row['synonym_nuance']}")
        with t2:
            st.write(f"**ğŸ¨ è¦–è¦ºæç¤ºï¼š** {row['visual_prompt']}")
            st.write(f"**ğŸ‘” ç¤¾æœƒæ„Ÿï¼š** {row['social_status']} | **ğŸŒ¡ï¸ æƒ…ç·’å€¼ï¼š** {row['emotional_tone']}")
        with t3:
            st.write(f"**ğŸ™ï¸ è¡—é ­ç”¨æ³•ï¼š** {row['street_usage']}")
            st.write(f"**ğŸ”— å¸¸ç”¨æ­é…ï¼š** {row['collocation']}")
            if row['usage_warning']:
                st.error(f"âš ï¸ ä½¿ç”¨è­¦å‘Šï¼š{row['usage_warning']}")

# ==========================================
# 4. é é¢é‚è¼¯
# ==========================================
def page_ai_lab():
    st.title("ğŸ”¬ Kadowsella è§£ç¢¼å¯¦é©—å®¤")
    st.write("è¼¸å…¥æ–°çŸ¥è­˜ï¼ŒAI å°‡è‡ªå‹•å¡«å¯« 20 æ¬„ä½ä¸¦å­˜å…¥ä½ çš„ **MyDB** æ›¸æ¶ã€‚")
    
    col_input, col_check = st.columns([3, 1])
    with col_input:
        new_word = st.text_input("è¼¸å…¥æƒ³è§£ç¢¼çš„å–®å­—æˆ–çŸ¥è­˜é»ï¼š", placeholder="ä¾‹å¦‚: 'Entropy' æˆ– 'é‡å­åŠ›å­¸'...")
    with col_check:
        # æ–°å¢ï¼šå¼·åˆ¶åˆ·æ–°é–‹é—œ
        st.write("") # æ’ç‰ˆç”¨
        st.write("") 
        force_refresh = st.checkbox("ğŸ”„ å¼·åˆ¶åˆ·æ–°\n(è¦†è“‹èˆŠè³‡æ–™)", value=False)
    
    if st.button("å•Ÿå‹•ä¸‰ä½ä¸€é«”è§£ç¢¼", type="primary"):
        if not new_word:
            st.warning("è«‹å…ˆè¼¸å…¥å…§å®¹ã€‚")
            return

        # --- æ­¥é©Ÿ 1: å…ˆæª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²æœ‰æ­¤å­— ---
        conn = st.connection("gsheets", type=GSheetsConnection)
        url = get_spreadsheet_url()
        existing_data = conn.read(spreadsheet=url, ttl=0)
        
        # æª¢æŸ¥å–®å­—æ˜¯å¦å­˜åœ¨ (ä¸åˆ†å¤§å°å¯«æ¯”è¼ƒå®‰å…¨)
        # æ³¨æ„ï¼šé€™è£¡å‡è¨­ 'word' æ¬„ä½æ˜¯ç´¢å¼•éµ
        is_exist = False
        if not existing_data.empty:
            # è½‰å°å¯«æ¯”å°ï¼Œé¿å… Apple å’Œ apple é‡è¤‡
            match_mask = existing_data['word'].astype(str).str.lower() == new_word.lower()
            is_exist = match_mask.any()

        if is_exist and not force_refresh:
            st.warning(f"âš ï¸ ã€Œ{new_word}ã€å·²ç¶“åœ¨æ›¸æ¶ä¸Šäº†ï¼è‹¥è¦é‡æ–°è§£ç¢¼ï¼Œè«‹å‹¾é¸å³å´çš„ã€å¼·åˆ¶åˆ·æ–°ã€ã€‚")
            # é¡¯ç¤ºç¾æœ‰å¡ç‰‡çµ¦ä½¿ç”¨è€…çœ‹
            existing_row = existing_data[match_mask].iloc[0].to_dict()
            st.markdown("---")
            st.info("ğŸ‘‡ é€™æ˜¯ç›®å‰çš„åº«å­˜ç‰ˆæœ¬ï¼š")
            show_encyclopedia_card(existing_row)
            return

        # --- æ­¥é©Ÿ 2: AI ç”Ÿæˆ ---
        with st.spinner(f'æ­£åœ¨ç‚ºã€Œ{new_word}ã€é€²è¡Œæ·±åº¦è§£ç¢¼...'):
            try:
                # å‘¼å« AI
                raw_res = ai_decode_and_save(new_word)
                
                # æ­£å‰‡è§£æ
                match = re.search(r'\{.*\}', raw_res, re.DOTALL)
                if not match:
                    st.error("AI è¼¸å‡ºæ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æ JSONã€‚")
                    st.code(raw_res)
                    return
                
                clean_json = match.group(0)
                res_data = json.loads(clean_json)

                # --- æ­¥é©Ÿ 3: è³‡æ–™è¦†å¯«é‚è¼¯ ---
                if is_exist and force_refresh:
                    # åˆªé™¤èˆŠè³‡æ–™ï¼šä¿ç•™ "ä¸ç­‰æ–¼" è©²å–®å­—çš„è¡Œ
                    existing_data = existing_data[~match_mask]
                    st.toast(f"ğŸ—‘ï¸ å·²ç§»é™¤èˆŠç‰ˆã€Œ{new_word}ã€ï¼Œæ­£åœ¨å¯«å…¥æ–°ç‰ˆ...", icon="Rg")

                # åˆä½µæ–°è³‡æ–™
                new_row = pd.DataFrame([res_data])
                updated_df = pd.concat([existing_data, new_row], ignore_index=True)
                
                # å¯«å› Google Sheets
                conn.update(spreadsheet=url, data=updated_df)
                
                st.success(f"ğŸ‰ æ›´æ–°å®Œæˆï¼ã€Œ{new_word}ã€å·²åˆ·æ–°ä¸¦å­˜å…¥æ›¸æ¶ã€‚")
                st.balloons()
                
                st.markdown("---")
                show_encyclopedia_card(res_data)

            except Exception as e:
                st.error(f"è§£ç¢¼éç¨‹å‡ºéŒ¯: {e}")
def page_home(df):
    st.markdown("<h1 style='text-align: center;'>Etymon Decoder</h1>", unsafe_allow_html=True)
    st.write("---")
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ“š ç¸½å–®å­—é‡", len(df))
    c2.metric("ğŸ·ï¸ åˆ†é¡ä¸»é¡Œ", df['category'].nunique() if not df.empty else 0)
    c3.metric("ğŸ§© ç¨ç‰¹å­—æ ¹", df['roots'].nunique() if not df.empty else 0)
    st.info("ğŸ‘ˆ è«‹å¾å·¦å´é¸å–®é€²å…¥ã€Œè§£ç¢¼å¯¦é©—å®¤ã€æ“´å……ä½ çš„çŸ¥è­˜åº«ã€‚")

def page_learn_search(df):
    st.title("ğŸ“– å­¸ç¿’èˆ‡æœå°‹")
    if df.empty:
        st.warning("ç›®å‰æ›¸æ¶æ˜¯ç©ºçš„ã€‚")
        return

    tab_card, tab_list = st.tabs(["ğŸ² éš¨æ©Ÿæ¢ç´¢", "ğŸ” è³‡æ–™åº«åˆ—è¡¨"])
    
    with tab_card:
        cats = ["å…¨éƒ¨"] + sorted(df['category'].unique().tolist())
        sel_cat = st.selectbox("é¸æ“‡å­¸ç¿’åˆ†é¡", cats)
        f_df = df if sel_cat == "å…¨éƒ¨" else df[df['category'] == sel_cat]

        if st.button("ä¸‹ä¸€å€‹å–®å­— (Next Word) â”", use_container_width=True, type="primary"):
            st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()
            st.rerun()

        if 'curr_w' not in st.session_state and not f_df.empty:
            st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()

        if 'curr_w' in st.session_state:
            show_encyclopedia_card(st.session_state.curr_w)

    with tab_list:
        search = st.text_input("ğŸ” æœå°‹æ›¸æ¶å…§å®¹...")
        if search:
            mask = df.astype(str).apply(lambda x: x.str.contains(search, case=False)).any(axis=1)
            display_df = df[mask]
        else:
            display_df = df.head(50)
        st.dataframe(display_df[['word', 'definition', 'roots', 'category', 'native_vibe']], use_container_width=True)

def page_quiz(df):
    st.title("ğŸ§  å­—æ ¹è¨˜æ†¶æŒ‘æˆ°")
    if df.empty: return
    
    cat = st.selectbox("é¸æ“‡æ¸¬é©—ç¯„åœ", df['category'].unique())
    pool = df[df['category'] == cat]
    
    if st.button("ğŸ² æŠ½ä¸€é¡Œ", use_container_width=True):
        st.session_state.q = pool.sample(1).iloc[0].to_dict()
        st.session_state.show_ans = False

    if 'q' in st.session_state:
        st.markdown(f"### â“ è«‹å•é€™å°æ‡‰å“ªå€‹å–®å­—ï¼Ÿ")
        st.info(st.session_state.q['definition'])
        st.write(f"**æç¤º (å­—æ ¹):** {st.session_state.q['roots']} ({st.session_state.q['meaning']})")
        
        if st.button("æ­æ›‰ç­”æ¡ˆ"):
            st.session_state.show_ans = True
        
        if st.session_state.show_ans:
            st.success(f"ğŸ’¡ ç­”æ¡ˆæ˜¯ï¼š**{st.session_state.q['word']}**")
            speak(st.session_state.q['word'], "quiz")
            st.write(f"çµæ§‹æ‹†è§£ï¼š`{st.session_state.q['breakdown']}`")

# ==========================================
# 5. ä¸»ç¨‹å¼å…¥å£
# ==========================================
def main():
    inject_custom_css()
    
    st.sidebar.title("Kadowsella")
    page = st.sidebar.radio("åŠŸèƒ½é¸å–®", ["é¦–é ", "å­¸ç¿’èˆ‡æœå°‹", "æ¸¬é©—æ¨¡å¼", "ğŸ”¬ AI è§£ç¢¼å¯¦é©—å®¤"])
    st.sidebar.markdown("---")
    
    # è¼‰å…¥æ›¸æ¶
    df = load_db()
    
    if page == "é¦–é ":
        page_home(df)
    elif page == "å­¸ç¿’èˆ‡æœå°‹":
        page_learn_search(df)
    elif page == "æ¸¬é©—æ¨¡å¼":
        page_quiz(df)
    elif page == "ğŸ”¬ AI è§£ç¢¼å¯¦é©—å®¤":
        page_ai_lab()
        
    st.sidebar.caption("v2.5 Pro è‡ªç”¨ç‰ˆ")

if __name__ == "__main__":
    main()
