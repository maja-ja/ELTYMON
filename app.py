import streamlit as st
import pandas as pd
import base64
import time
import json
import re  # æ–°å¢ï¼šç”¨æ–¼ç²¾æº–æå– JSON
from io import BytesIO
from gtts import gTTS
import google.generativeai as genai
from streamlit_gsheets import GSheetsConnection

# ==========================================
# 1. æ ¸å¿ƒé…ç½®èˆ‡è¦–è¦ºç¾åŒ– (CSS)
# ==========================================
st.set_page_config(page_title="Etymon Decoder v2.5", page_icon="ğŸ§©", layout="wide")
def inject_custom_css():
    st.markdown("""
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Noto+Sans+TC:wght@500;700&display=swap');
            
            /* 1. æ‹†è§£å€å¡Šæ¨£å¼ */
            .breakdown-container {
                font-family: 'Inter', 'Noto Sans TC', sans-serif; 
                font-size: 1.8rem !important; 
                font-weight: 700;
                letter-spacing: 1px;
                background: linear-gradient(135deg, #1E88E5 0%, #1565C0 100%);
                color: #FFFFFF;
                padding: 12px 30px;
                border-radius: 15px;
                display: inline-block;
                margin: 20px 0;
                box-shadow: 0 4px 15px rgba(30, 136, 229, 0.3);
                border: 1px solid rgba(255, 255, 255, 0.2);
            }
            .breakdown-container span.operator {
                color: #BBDEFB;
                margin: 0 8px;
            }

            /* 2. æ‰‹æ©ŸéŸ¿æ‡‰å¼èª¿æ•´ */
            @media (max-width: 600px) {
                .breakdown-container {
                    font-size: 1.2rem !important;
                    display: block;
                    text-align: center;
                }
            }

            /* 3. å–®å­—èˆ‡éŸ³æ¨™ */
            .hero-word { font-size: 2.5rem; font-weight: 800; color: #333; }
            /* å¦‚æœåœ¨æ·±è‰²æ¨¡å¼ä¸‹ï¼Œå–®å­—æ¨™é¡Œä¹Ÿè¦ç¢ºä¿çœ‹å¾—åˆ° */
            @media (prefers-color-scheme: dark) {
                .hero-word { color: #FFF; }
            }
            .hero-phonetic { font-size: 1.2rem; color: #888; font-family: monospace; margin-bottom: 10px; }

            /* 4. [ä¿®æ­£é»] èªæ„Ÿå€å¡Šï¼šå¼·åˆ¶æ·±è‰²æ–‡å­— */
            .vibe-box { 
                background-color: #E3F2FD; 
                padding: 15px; 
                border-radius: 10px; 
                border-left: 5px solid #2196F3; 
                
                /* é€™è£¡å¼·åˆ¶æŒ‡å®šæ–‡å­—é¡è‰²ç‚ºæ·±ç°ï¼Œé¿å…è¢«æ·±è‰²æ¨¡å¼åç™½ */
                color: #333333 !important; 
            }
            /* ç¢ºä¿ box è£¡é¢çš„æ¨™é¡Œä¹Ÿæ˜¯æ·±è—è‰² */
            .vibe-box h4 {
                color: #1565C0 !important;
            }
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. å·¥å…·å‡½å¼
# ==========================================

def speak(text, key_suffix=""):
    try:
        if not text: return
        
        # --- [æ–°å¢] è‹±èªæ¿¾ç¶² ---
        # åªä¿ç•™ A-Z, a-z, 0-9, ç©ºæ ¼,é€£å­—è™Ÿ(-), æ’‡è™Ÿ(')
        # é€™æ¨£ "Quantum Mechanics (é‡å­åŠ›å­¸)" è®Šæˆ "Quantum Mechanics"
        # è€Œ "é»‘æ´" è®Šæˆ "" (ç©ºå­—ä¸²)ï¼Œå°±ä¸æœƒç™¼å‡ºæ€ªè²
        english_only = re.sub(r"[^a-zA-Z0-9\s\-\']", "", str(text)).strip()
        
        # å¦‚æœæ¿¾å®Œæ²’æ±è¥¿ï¼ˆä»£è¡¨å…¨æ˜¯ä¸­æ–‡ï¼‰ï¼Œå°±ç›´æ¥è·³å‡ºï¼Œä¸æ’­æ”¾
        if not english_only:
            return
            
        tts = gTTS(text=english_only, lang='en')
        fp = BytesIO()
        tts.write_to_fp(fp)
        audio_base64 = base64.b64encode(fp.getvalue()).decode()
        unique_id = f"audio_{int(time.time())}_{key_suffix}"
        st.components.v1.html(f'<audio id="{unique_id}" autoplay="true" style="display:none;"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio><script>document.getElementById("{unique_id}").play();</script>', height=0)
    except Exception as e: st.error(f"èªéŸ³éŒ¯èª¤: {e}")

def get_spreadsheet_url():
    """å®‰å…¨åœ°ç²å–è©¦ç®—è¡¨ç¶²å€ï¼Œç›¸å®¹å…©ç¨® secrets æ ¼å¼"""
    try:
        # å„ªå…ˆå˜—è©¦ connections çµæ§‹
        return st.secrets["connections"]["gsheets"]["spreadsheet"]
    except:
        try:
            # å‚™ç”¨ï¼šç›´æ¥çµæ§‹
            return st.secrets["gsheets"]["spreadsheet"]
        except:
            st.error("æ‰¾ä¸åˆ° spreadsheet è¨­å®šï¼Œè«‹æª¢æŸ¥ secrets.toml")
            return ""

@st.cache_data(ttl=60)
def load_db():
    COL_NAMES = [
        'category', 'roots', 'meaning', 'word', 'breakdown', 
        'definition', 'phonetic', 'example', 'translation', 'native_vibe',
        'synonym_nuance', 'visual_prompt', 'social_status', 'emotional_tone', 'street_usage',
        'collocation', 'etymon_story', 'usage_warning', 'memory_hook', 'audio_tag'
    ]
    
    # ä½¿ç”¨ GSheetsConnection è®€å– (æ¯” pd.read_csv æ›´ç©©å®šä¸”èƒ½åˆ©ç”¨å¿«å–)
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        url = get_spreadsheet_url()
        df = conn.read(spreadsheet=url, ttl=60) # åŠ å…¥ TTL é¿å…é »ç¹è®€å–
        
        # å¼·åˆ¶å°é½Š 20 æ¬„
        for col in COL_NAMES:
            if col not in df.columns:
                df[col] = ""
        
        # åªä¿ç•™é€™ 20 å€‹æ¬„ä½ä¸¦å»é™¤éå–®å­—è¡Œ
        df = df[COL_NAMES].dropna(subset=['word']).fillna("").reset_index(drop=True)
        return df
    except Exception as e:
        # Fallback: å¦‚æœé€£ç·šå¤±æ•—ï¼Œå›å‚³ç©ºè¡¨ä»¥å… App å´©æ½°
        st.error(f"è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        return pd.DataFrame(columns=COL_NAMES)

# ==========================================
# 3. AI è§£ç¢¼æ ¸å¿ƒ (è‡ªç”¨è§£é–ç‰ˆ)
# ==========================================
def ai_decode_and_save(input_text, fixed_category):
    """
    æ ¸å¿ƒè§£ç¢¼å‡½å¼ï¼šå°‡ Prompt ç›´æ¥å¯«å…¥ç¨‹å¼ç¢¼ï¼Œç¢ºä¿åŸ·è¡Œç©©å®šã€‚
    """
    # å¾ secrets è®€å– API Key
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        st.error("âŒ æ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹æª¢æŸ¥ Streamlit Secrets è¨­å®šã€‚")
        return None

    genai.configure(api_key=api_key)
    
    # å®‰å…¨è¨­å®šï¼šè§£é™¤éæ¿¾
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    # å®šç¾©ç¡¬ç·¨ç¢¼ Prompt
    SYSTEM_PROMPT = f"""
    Role: å…¨é ˜åŸŸçŸ¥è­˜è§£æ§‹å°ˆå®¶ (Polymath Decoder).
    Task: æ·±åº¦åˆ†æè¼¸å…¥å…§å®¹ï¼Œä¸¦å°‡å…¶è§£æ§‹ç‚ºé«˜å“è³ªã€çµæ§‹åŒ–çš„ç™¾ç§‘çŸ¥è­˜ JSONã€‚
    
    ã€é ˜åŸŸé–å®šã€‘ï¼šä½ ç›®å‰çš„èº«ä»½æ˜¯ã€Œ{fixed_category}ã€å°ˆå®¶ï¼Œè«‹å‹™å¿…ä»¥æ­¤å°ˆæ¥­è¦–è§’é€²è¡Œè§£æ§‹ã€è©•è«–èˆ‡æ¨å°ã€‚

    ## è™•ç†é‚è¼¯ (Field Mapping Strategy):
    1. category: å¿…é ˆå›ºå®šå¡«å¯«ç‚ºã€Œ{fixed_category}ã€ã€‚
    2. word: æ ¸å¿ƒæ¦‚å¿µåç¨± (æ¨™é¡Œ)ã€‚
    3. roots: åº•å±¤é‚è¼¯ / æ ¸å¿ƒåŸç† / é—œéµå…¬å¼ã€‚**ã€é‡è¦ã€‘**ï¼šè‹¥æœ‰æ•¸å­¸å…¬å¼ï¼Œè«‹ä½¿ç”¨ LaTeX æ ¼å¼ä¸¦ç”¨ $ åŒ…åœï¼Œä¾‹å¦‚ï¼š$E=mc^2$ã€‚
    4. meaning: è©²æ¦‚å¿µè§£æ±ºäº†ä»€éº¼æ ¸å¿ƒç—›é»æˆ–å…¶å­˜åœ¨çš„æœ¬è³ªæ„ç¾©ã€‚
    5. breakdown: çµæ§‹æ‹†è§£ã€‚æ­¥é©Ÿæµç¨‹æˆ–çµ„æˆè¦ç´ ã€‚æ¶‰åŠæ¨å°æ™‚è«‹é€æ­¥æ¢åˆ—ã€‚
    6. definition: ç”¨äº”æ­²å°å­©éƒ½èƒ½è½æ‡‚çš„è©± (ELI5) è§£é‡‹è©²æ¦‚å¿µã€‚
    7. phonetic: é—œéµå¹´ä»£ã€ç™¼æ˜äººåã€æˆ–è©²é ˜åŸŸçš„å°ˆæœ‰åè©ã€‚
    8. example: å…©å€‹ä»¥ä¸Šæœ€å…·ä»£è¡¨æ€§çš„å¯¦éš›æ‡‰ç”¨å ´æ™¯ã€‚
    9. translation: ç”Ÿæ´»é¡æ¯”ã€‚ç”¨ä¸€å€‹æ—¥å¸¸ç”Ÿæ´»çš„å ´æ™¯ä¾†æ¯”å–»é€™å€‹è¤‡é›œæ¦‚å¿µã€‚
    10. native_vibe: å°ˆå®¶è¦–è§’ / å…§è¡Œäººçš„å¿ƒæ³•ã€‚
    11. synonym_nuance: ç›¸ä¼¼æ¦‚å¿µå°æ¯”ã€‚å€åˆ†å®ƒèˆ‡æœ€å®¹æ˜“æ··æ·†çš„æ¦‚å¿µæœ‰ä½•ä¸åŒã€‚
    12. visual_prompt: è¦–è¦ºåŒ–åœ–æ™¯ã€‚æè¿°ä¸€å¼µèƒ½ä»£è¡¨è©²æ¦‚å¿µçš„æ§‹åœ–æˆ–æ„è±¡ã€‚
    13. social_status: åœ¨è©²é ˜åŸŸçš„é‡è¦æ€§è©•ç´šã€‚
    14. emotional_tone: å­¸ç¿’æ­¤çŸ¥è­˜çš„å¿ƒç†æ„Ÿå—ã€‚
    15. street_usage: é¿å‘æŒ‡å—ã€‚åˆå­¸è€…æœ€å®¹æ˜“çŠ¯çš„éŒ¯èª¤æˆ–å¸¸è¦‹çš„èªçŸ¥èª¤å€ã€‚
    16. collocation: é—œè¯åœ–è­œã€‚ä¸‰å€‹èˆ‡æ­¤æ¦‚å¿µç·Šå¯†ç›¸é—œçš„å»¶ä¼¸çŸ¥è­˜é»ã€‚
    17. etymon_story: æ­·å²è„ˆçµ¡ã€‚è©²æ¦‚å¿µæ˜¯å¦‚ä½•è¢«ç™¼ç¾æˆ–æ¼”è®Šè€Œä¾†çš„é—œéµç¬é–“ã€‚
    18. usage_warning: é‚Šç•Œæ¢ä»¶ã€‚åœ¨ä»€éº¼æƒ…æ³ä¸‹æ­¤æ¦‚å¿µä¸é©ç”¨æˆ–æœƒå¤±æ•ˆã€‚
    19. memory_hook: è¨˜æ†¶é‡‘å¥ã€‚ä¸€å¥è©±è®“ä½ æ°¸é è¨˜ä½é€™å€‹æ¦‚å¿µã€‚
    20. audio_tag: ç›¸é—œæ¨™ç±¤ (ä»¥ # é–‹é ­)ã€‚

    ## è¼¸å‡ºè¦ç¯„ (JSON å®‰å…¨æ€§èˆ‡è½‰ç¾©è¦æ±‚):
    1. å¿…é ˆè¼¸å‡ºåš´æ ¼åˆæ³•çš„ JSON æ ¼å¼ï¼Œå…§å®¹ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€ã€‚
    2. **ã€åæ–œç·šè½‰ç¾©ã€‘**ï¼šJSON å…§éƒ¨çš„åæ–œç·š `\\` å¿…é ˆç¶“éè½‰ç¾©ã€‚
       - æ‰€æœ‰çš„ LaTeX ç¬¦è™Ÿï¼ˆå¦‚ `\\frac`ï¼‰å¿…é ˆå¯«æˆ `\\\\frac` (å››å€‹åæ–œç·š)ã€‚
       - æ‰€æœ‰çš„è·¯å¾‘æˆ–æ™®é€šåæ–œç·šå¿…é ˆå¯«æˆ `\\\\`ã€‚
    3. **ã€æ›è¡Œè™•ç†ã€‘**ï¼šå­—ä¸²å…§åš´ç¦ç›´æ¥æ›è¡Œã€‚è«‹ä½¿ç”¨ `\\\\n` ä»£æ›¿æ›è¡Œç¬¦è™Ÿã€‚
    4. å¿…é ˆå¡«æ»¿ 20 å€‹æ¬„ä½ï¼Œå…§å®¹éœ€è©³ç›¡ä¸”å°ˆæ¥­ï¼Œåš´ç¦æ•·è¡ã€‚
    """

    try:
        model = genai.GenerativeModel('gemini-2.5-flash', safety_settings=safety_settings)
        final_prompt = f"{SYSTEM_PROMPT}\n\nè§£ç¢¼ç›®æ¨™ï¼šã€Œ{input_text}ã€"
        
        response = model.generate_content(final_prompt)
        
        if response and response.text:
            return response.text
        return None
    except Exception as e:
        st.error(f"Gemini API éŒ¯èª¤: {e}")
        return None
def show_encyclopedia_card(row):
    """ç¾åŒ–é¡¯ç¤ºå–®ä¸€çŸ¥è­˜çš„ç™¾ç§‘å¡ç‰‡ï¼Œæ”¯æ´ LaTeX å…¬å¼æ¸²æŸ“"""
    
    # --- 1. å­—ä¸²é è™•ç† (æ ¸å¿ƒä¿®å¾©) ---
    # å°‡ AI ç‚ºäº† JSON å®‰å…¨ç”Ÿæˆçš„é›™åæ–œç·šè½‰å›å–®åæ–œç·šï¼Œä¸¦è™•ç†æ›è¡Œ
    def clean_latex(text):
        if not text or text == "ç„¡": return text
        return str(text).replace('\\\\', '\\').replace('\\n', '\n')

    # é å…ˆè™•ç†éœ€è¦é¡¯ç¤ºå…¬å¼çš„æ¬„ä½
    row_word = str(row['word'])
    row_roots = clean_latex(row['roots'])
    row_breakdown = clean_latex(row['breakdown'])
    row_definition = clean_latex(row['definition'])
    row_example = clean_latex(row['example'])

    # --- 2. æ¨™é¡Œèˆ‡éŸ³æ¨™/å¹´ä»£ ---
    st.markdown(f"<div class='hero-word'>{row_word}</div>", unsafe_allow_html=True)
    
    # åˆ¤æ–·æ˜¯éŸ³æ¨™é‚„æ˜¯å¹´ä»£/äººå
    phonetic_val = str(row['phonetic'])
    if any(c in phonetic_val for c in "É™Ã¦ÉªÊŠ"):
        st.markdown(f"<div class='hero-phonetic'>/{phonetic_val}/</div>", unsafe_allow_html=True)
    else:
        st.markdown(f"<div class='hero-phonetic' style='color:#1E88E5;'>ğŸ“Œ {phonetic_val}</div>", unsafe_allow_html=True)
    
    # --- 3. å‹•ä½œæŒ‰éˆ•èˆ‡æ‹†è§£å€ ---
    col_a, col_b = st.columns([1, 4])
    with col_a:
        if st.button("ğŸ”Š æœ—è®€", key=f"spk_{row_word}_{int(time.time())}", use_container_width=True):
            speak(row_word, "card")
    with col_b:
        # è®“æ‹†è§£å€æ”¯æ´å…¬å¼æ¸²æŸ“ï¼ŒåŒæ™‚ä¿ç•™åŸæœ¬çš„é‹ç®—å­ç¾åŒ–
        styled_breakdown = row_breakdown.replace("+", "<span class='operator'>+</span>")
        st.markdown(f"<div class='breakdown-container'>{styled_breakdown}</div>", unsafe_allow_html=True)

    # --- 4. æ ¸å¿ƒå…§å®¹å€ (ä½¿ç”¨ st.markdown ç¢ºä¿ LaTeX è§¸ç™¼) ---
    st.write("---")
    c1, c2 = st.columns(2)
    with c1:
        st.info("### ğŸ¯ å®šç¾©èˆ‡è§£é‡‹")
        st.markdown(row_definition) 
        st.markdown(f"**ğŸ“ æ¡ˆä¾‹/æ¨å°ï¼š**\n{row_example}")
        st.caption(f"ï¼ˆ{row['translation']}ï¼‰")
        
    with c2:
        st.success("### ğŸ’¡ æ ¸å¿ƒåŸç†")
        st.markdown(row_roots)  # é€™è£¡æœƒæ¼‚äº®åœ°é¡¯ç¤º $E=mc^2$
        st.write(f"**æ„ç¾©ï¼š** {row['meaning']}")
        st.markdown(f"**ğŸª è¨˜æ†¶é‰¤å­ï¼š**\n{row['memory_hook']}")

    # --- 5. å°ˆå®¶èªæ„Ÿå€ ---
    if row['native_vibe'] and row['native_vibe'] != "ç„¡":
        st.markdown(f"""
            <div class='vibe-box'>
                <h4 style='margin-top:0;'>ğŸŒŠ å°ˆå®¶è¦–è§’ / å…§è¡Œå¿ƒæ³•</h4>
                <p style='font-size: 1.1rem; line-height: 1.6;'>{row['native_vibe']}</p>
            </div>
        """, unsafe_allow_html=True)

    # --- 6. æ›´å¤šç´°ç¯€ (éš±è—é¸å–®) ---
    with st.expander("ğŸ” æŸ¥çœ‹æ·±åº¦ç™¾ç§‘èˆ‡é¿å‘æŒ‡å—"):
        st.write(f"**âš–ï¸ è¾¨æï¼š** {row['synonym_nuance']}")
        st.write(f"**ğŸ›ï¸ èµ·æºæ•…äº‹ï¼š** {row['etymon_story']}")
        st.write(f"**âš ï¸ ä½¿ç”¨æ³¨æ„ï¼š** {row['usage_warning']}")
        st.write(f"**ğŸ™ï¸ é—œè¯åœ–è­œï¼š** {row['collocation']}")
    with st.expander("ğŸ“š æŸ¥çœ‹æ·±åº¦ç™¾ç§‘ (æ–‡åŒ–ã€ç¤¾æœƒã€è¡—é ­å¯¦æˆ°)"):
        t1, t2, t3 = st.tabs(["ğŸ›ï¸ å­—æºæ–‡åŒ–", "ğŸ‘” ç¤¾æœƒåœ°ä½", "ğŸ˜ è¡—é ­å¯¦æˆ°"])
        with t1:
            st.write(f"**ğŸ“œ å­—æºæ•…äº‹ï¼š** {row['etymon_story']}")
            st.write(f"**âš–ï¸ åŒç¾©è©è¾¨æï¼š** {row['synonym_nuance']}")
        with t2:
            st.write(f"**ğŸ¨ è¦–è¦ºæç¤ºï¼š** {row['visual_prompt']}")
            st.write(f"**ğŸ‘” ç¤¾æœƒæ„Ÿï¼š** {row['social_status']} | **ğŸŒ¡ï¸ æƒ…ç·’å€¼ï¼š** {row['emotional_tone']}")
        with t3:
            st.write(f"**ğŸ™ï¸ è¡—é ­ç”¨æ³•ï¼š** {row['street_usage']}")
            st.write(f"**ğŸ”— å¸¸ç”¨æ­é…ï¼š** {row['collocation']}")
            if row['usage_warning']:
                st.error(f"âš ï¸ ä½¿ç”¨è­¦å‘Šï¼š{row['usage_warning']}")

# ==========================================
# 4. é é¢é‚è¼¯
# ==========================================
def page_ai_lab():
    st.title("ğŸ”¬ Kadowsella è§£ç¢¼å¯¦é©—å®¤")
    
    # 24 å€‹ç²¾é¸å›ºå®šé ˜åŸŸ
    FIXED_CATEGORIES = [
        "è‹±èªè¾­æº", "èªè¨€é‚è¼¯", "ç‰©ç†ç§‘å­¸", "ç”Ÿç‰©é†«å­¸", "å¤©æ–‡åœ°è³ª", "æ•¸å­¸é‚è¼¯", 
        "æ­·å²æ–‡æ˜", "æ”¿æ²»æ³•å¾‹", "ç¤¾æœƒå¿ƒç†", "å“²å­¸å®—æ•™", "è»äº‹æˆ°ç•¥", "è€ƒå¤ç™¼ç¾",
        "å•†æ¥­å•†æˆ°", "é‡‘èæŠ•è³‡", "ç¨‹å¼é–‹ç™¼", "äººå·¥æ™ºæ…§", "ç”¢å“è¨­è¨ˆ", "æ•¸ä½è¡ŒéŠ·",
        "è—è¡“ç¾å­¸", "å½±è¦–æ–‡å­¸", "æ–™ç†é£Ÿè§€", "é‹å‹•å¥èº«", "æµè¡Œæ–‡åŒ–", "é›œé¡", "è‡ªå®šç¾©"
    ]
    
    col_input, col_cat = st.columns([2, 1])
    with col_input:
        new_word = st.text_input("è¼¸å…¥è§£ç¢¼ä¸»é¡Œï¼š", placeholder="ä¾‹å¦‚: 'äºŒæ¬¡å‡½æ•¸é ‚é»å¼'...")
    with col_cat:
        selected_category = st.selectbox("é¸å®šé ˜åŸŸæ¨™ç±¤", FIXED_CATEGORIES)
        
    if selected_category == "è‡ªå®šç¾©":
        custom_cat = st.text_input("è«‹è¼¸å…¥è‡ªå®šç¾©é ˜åŸŸåç¨±ï¼š")
        final_category = custom_cat if custom_cat else "æœªåˆ†é¡"
    else:
        final_category = selected_category

    force_refresh = st.checkbox("ğŸ”„ å¼·åˆ¶åˆ·æ–° (è¦†è“‹èˆŠè³‡æ–™)")
    
    if st.button("å•Ÿå‹•è§£ç¢¼", type="primary"):
        if not new_word:
            st.warning("è«‹å…ˆè¼¸å…¥å…§å®¹ã€‚")
            return

        conn = st.connection("gsheets", type=GSheetsConnection)
        url = get_spreadsheet_url()
        existing_data = conn.read(spreadsheet=url, ttl=0)
        
        is_exist = False
        if not existing_data.empty:
            match_mask = existing_data['word'].astype(str).str.lower() == new_word.lower()
            is_exist = match_mask.any()

        if is_exist and not force_refresh:
            st.warning(f"âš ï¸ ã€Œ{new_word}ã€å·²åœ¨æ›¸æ¶ä¸Šã€‚")
            show_encyclopedia_card(existing_data[match_mask].iloc[0].to_dict())
            return

        with st.spinner(f'æ­£åœ¨ä»¥ã€{final_category}ã€‘è¦–è§’é€²è¡Œä¸‰ä½ä¸€é«”è§£ç¢¼...'):
            raw_res = ai_decode_and_save(new_word, final_category)
            
            if raw_res is None:
                st.error("AI ç„¡å›æ‡‰ã€‚")
                return

            try:
                # 1. æå– JSON å€å¡Š
                match = re.search(r'\{.*\}', raw_res, re.DOTALL)
                if not match:
                    st.error("è§£æå¤±æ•—ï¼šæ‰¾ä¸åˆ° JSON çµæ§‹ã€‚")
                    return
                
                json_str = match.group(0)

                # 2. [é—œéµé˜²ç¦¦] ä¿®å¾©æ½›åœ¨çš„éæ³•è½‰ç¾©å­—å…ƒ
                # ä½¿ç”¨ strict=False å…è¨±è§£æå™¨è™•ç†ä¸€äº›ä¸åˆè¦çš„æ§åˆ¶å­—å…ƒ
                try:
                    res_data = json.loads(json_str, strict=False)
                except json.JSONDecodeError:
                    # å¦‚æœ strict=False é‚„æ˜¯å¤±æ•—ï¼Œé€²è¡Œæš´åŠ›å­—ä¸²ä¿®å¾©
                    fixed_json = json_str.replace('\n', '\\n').replace('\r', '\\r')
                    res_data = json.loads(fixed_json, strict=False)

                # 3. æ›´æ–° Google Sheets
                if is_exist and force_refresh:
                    existing_data = existing_data[~match_mask]
                
                new_row = pd.DataFrame([res_data])
                updated_df = pd.concat([existing_data, new_row], ignore_index=True)
                
                conn.update(spreadsheet=url, data=updated_df)
                st.success(f"ğŸ‰ ã€Œ{new_word}ã€è§£ç¢¼å®Œæˆä¸¦å·²å­˜å…¥é›²ç«¯ï¼")
                st.balloons()
                show_encyclopedia_card(res_data)

            except Exception as e:
                st.error(f"âš ï¸ è™•ç†å¤±æ•—: {e}")
                with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“šå›å ±éŒ¯èª¤"):
                    st.code(raw_res)
def page_home(df):
    st.markdown("<h1 style='text-align: center;'>Etymon Decoder</h1>", unsafe_allow_html=True)
    st.write("---")
    
    # 1. æ•¸æ“šå„€è¡¨æ¿
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ“š ç¸½å–®å­—é‡", len(df))
    c2.metric("ğŸ·ï¸ åˆ†é¡ä¸»é¡Œ", df['category'].nunique() if not df.empty else 0)
    c3.metric("ğŸ§© ç¨ç‰¹å­—æ ¹", df['roots'].nunique() if not df.empty else 0)
    
    st.write("---")

    # 2. [æ–°å¢] éš¨æ©Ÿæ¨è–¦å±•ç¤ºå€
    st.subheader("ğŸ’¡ ä»Šæ—¥éš¨æ©Ÿæ¨è–¦")
    
    if not df.empty:
        # å¦‚æœè³‡æ–™åº«å°‘æ–¼ 3 ç­†ï¼Œå°±å…¨ç§€ï¼›å¦å‰‡éš¨æ©ŸæŠ½ 3 ç­†
        sample_count = min(3, len(df))
        #æ¯æ¬¡é‡æ–°æ•´ç†é é¢éƒ½æœƒè®Šå‹•
        sample = df.sample(sample_count) 
        
        # ä½¿ç”¨ 3 å€‹æ¬„ä½ä¸¦æ’é¡¯ç¤ºï¼Œçœ‹èµ·ä¾†æ›´åƒå¡ç‰‡
        cols = st.columns(3)
        for i, (index, row) in enumerate(sample.iterrows()):
            with cols[i % 3]: # ç¢ºä¿åœ¨ 3 æ¬„å…§å¾ªç’°
                with st.container(border=True): # åŠ å€‹é‚Šæ¡†æ›´æœ‰è³ªæ„Ÿ
                    st.markdown(f"### {row['word']}")
                    st.caption(f"ğŸ·ï¸ {row['category']}")
                    st.write(f"**å®šç¾©ï¼š** {row['definition']}")
                    st.write(f"**æ ¸å¿ƒï¼š** {row['roots']}")
                    # é€™è£¡å¯ä»¥åŠ ä¸€å€‹å°æŒ‰éˆ•ï¼Œé»äº†æœ—è®€è©²å–®å­—
                    if st.button("ğŸ”Š", key=f"home_spk_{row['word']}"):
                        speak(row['word'], "home")
    else:
        st.info("ğŸ‘ˆ è³‡æ–™åº«ç›®å‰æ˜¯ç©ºçš„ï¼Œè«‹å¾å·¦å´é€²å…¥ã€Œè§£ç¢¼å¯¦é©—å®¤ã€æ–°å¢ç¬¬ä¸€ç­†çŸ¥è­˜ï¼")

    st.write("---")
    st.info("ğŸ‘ˆ é»æ“Šå·¦å´é¸å–®é€²å…¥ã€Œå­¸ç¿’èˆ‡æœå°‹ã€æŸ¥çœ‹å®Œæ•´è³‡æ–™åº«ã€‚")

def page_learn_search(df):
    st.title("ğŸ“– å­¸ç¿’èˆ‡æœå°‹")
    if df.empty:
        st.warning("ç›®å‰æ›¸æ¶æ˜¯ç©ºçš„ã€‚")
        return

    tab_card, tab_list = st.tabs(["ğŸ² éš¨æ©Ÿæ¢ç´¢", "ğŸ” è³‡æ–™åº«åˆ—è¡¨"])
    
    with tab_card:
        cats = ["å…¨éƒ¨"] + sorted(df['category'].unique().tolist())
        sel_cat = st.selectbox("é¸æ“‡å­¸ç¿’åˆ†é¡", cats)
        f_df = df if sel_cat == "å…¨éƒ¨" else df[df['category'] == sel_cat]

        if st.button("ä¸‹ä¸€å€‹å–®å­— (Next Word) â”", use_container_width=True, type="primary"):
            st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()
            st.rerun()

        if 'curr_w' not in st.session_state and not f_df.empty:
            st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()

        if 'curr_w' in st.session_state:
            show_encyclopedia_card(st.session_state.curr_w)

    with tab_list:
        search = st.text_input("ğŸ” æœå°‹æ›¸æ¶å…§å®¹...")
        if search:
            mask = df.astype(str).apply(lambda x: x.str.contains(search, case=False)).any(axis=1)
            display_df = df[mask]
        else:
            display_df = df.head(50)
        st.dataframe(display_df[['word', 'definition', 'roots', 'category', 'native_vibe']], use_container_width=True)

def page_quiz(df):
    st.title("ğŸ§  å­—æ ¹è¨˜æ†¶æŒ‘æˆ°")
    if df.empty: return
    
    cat = st.selectbox("é¸æ“‡æ¸¬é©—ç¯„åœ", df['category'].unique())
    pool = df[df['category'] == cat]
    
    if st.button("ğŸ² æŠ½ä¸€é¡Œ", use_container_width=True):
        st.session_state.q = pool.sample(1).iloc[0].to_dict()
        st.session_state.show_ans = False

    if 'q' in st.session_state:
        st.markdown(f"### â“ è«‹å•é€™å°æ‡‰å“ªå€‹å–®å­—ï¼Ÿ")
        st.info(st.session_state.q['definition'])
        st.write(f"**æç¤º (å­—æ ¹):** {st.session_state.q['roots']} ({st.session_state.q['meaning']})")
        
        if st.button("æ­æ›‰ç­”æ¡ˆ"):
            st.session_state.show_ans = True
        
        if st.session_state.show_ans:
            st.success(f"ğŸ’¡ ç­”æ¡ˆæ˜¯ï¼š**{st.session_state.q['word']}**")
            speak(st.session_state.q['word'], "quiz")
            st.write(f"çµæ§‹æ‹†è§£ï¼š`{st.session_state.q['breakdown']}`")

# ==========================================
# 5. ä¸»ç¨‹å¼å…¥å£
# ==========================================
def main():
    inject_custom_css()
    
    st.sidebar.title("Kadowsella")
    
    # --- [è´ŠåŠ©å€å¡Š] é›™åˆ€æµ ---
    st.sidebar.markdown("""
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 12px; border: 1px solid #e9ecef; margin-bottom: 25px;">
            <p style="text-align: center; margin-bottom: 12px; font-weight: bold; color: #444;">ğŸ’– æ”¯æŒé–‹ç™¼è€…</p>
            <a href="https://www.buymeacoffee.com/kadowsella" target="_blank" style="text-decoration: none;">
                <div style="background-color: #FFDD00; color: #000; padding: 8px; border-radius: 8px; text-align: center; font-weight: bold; margin-bottom: 8px; font-size: 0.9rem;">
                    â˜• Buy Me a Coffee
                </div>
            </a>
            <a href="https://p.ecpay.com.tw/kadowsella20" target="_blank" style="text-decoration: none;">
                <div style="background: linear-gradient(90deg, #28C76F 0%, #81FBB8 100%); color: white; padding: 8px; border-radius: 8px; text-align: center; font-weight: bold; font-size: 0.9rem;">
                    è´ŠåŠ©ä¸€ç¢—ç±³ç³•ï¼
                </div>
            </a>
        </div>
    """, unsafe_allow_html=True)
    
    # --- [ç®¡ç†å“¡ç™»å…¥] ---
    is_admin = False
    with st.sidebar.expander("ğŸ” ç®¡ç†å“¡ç™»å…¥", expanded=False):
        input_pass = st.text_input("è¼¸å…¥å¯†ç¢¼", type="password")
        if input_pass == st.secrets.get("ADMIN_PASSWORD", "0000"):
            is_admin = True
            st.success("ğŸ”“ ä¸Šå¸æ¨¡å¼å•Ÿå‹•")

    # --- [é¸å–®é‚è¼¯] ---
    if is_admin:
        menu_options = ["é¦–é ", "å­¸ç¿’èˆ‡æœå°‹", "æ¸¬é©—æ¨¡å¼", "ğŸ”¬ è§£ç¢¼å¯¦é©—å®¤"]
        if st.sidebar.button("ğŸ”„ å¼·åˆ¶åŒæ­¥é›²ç«¯", help="æ¸…é™¤ App å¿«å–"):
            st.cache_data.clear()
            st.rerun()
    else:
        menu_options = ["é¦–é ", "å­¸ç¿’èˆ‡æœå°‹", "æ¸¬é©—æ¨¡å¼"]
    
    page = st.sidebar.radio("åŠŸèƒ½é¸å–®", menu_options)
    st.sidebar.markdown("---")
    
    df = load_db()
    
    if page == "é¦–é ":
        page_home(df)
    elif page == "å­¸ç¿’èˆ‡æœå°‹":
        page_learn_search(df)
    elif page == "æ¸¬é©—æ¨¡å¼":
        page_quiz(df)
    elif page == "ğŸ”¬ è§£ç¢¼å¯¦é©—å®¤":
        if is_admin:
            page_ai_lab()
        else:
            st.error("â›” è«‹å…ˆç™»å…¥")

    status = "ğŸ”´ ç®¡ç†å“¡" if is_admin else "ğŸŸ¢ è¨ªå®¢"
    st.sidebar.caption(f"v3.0 Ultimate | {status}")

if __name__ == "__main__":
    main()
