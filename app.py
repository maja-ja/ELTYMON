import streamlit as st
import pandas as pd
import base64
import time
import json
import re  # æ–°å¢ï¼šç”¨æ–¼ç²¾æº–æå– JSON
from io import BytesIO
from gtts import gTTS
import google.generativeai as genai
from streamlit_gsheets import GSheetsConnection

# ==========================================
# 1. æ ¸å¿ƒé…ç½®èˆ‡è¦–è¦ºç¾åŒ– (CSS)
# ==========================================
st.set_page_config(page_title="Etymon Decoder v2.5", page_icon="ğŸ§©", layout="wide")
def inject_custom_css():
    st.markdown("""
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Noto+Sans+TC:wght@500;700&display=swap');
            
            /* 1. æ‹†è§£å€å¡Šæ¨£å¼ */
            .breakdown-container {
                font-family: 'Inter', 'Noto Sans TC', sans-serif; 
                font-size: 1.8rem !important; 
                font-weight: 700;
                letter-spacing: 1px;
                background: linear-gradient(135deg, #1E88E5 0%, #1565C0 100%);
                color: #FFFFFF;
                padding: 12px 30px;
                border-radius: 15px;
                display: inline-block;
                margin: 20px 0;
                box-shadow: 0 4px 15px rgba(30, 136, 229, 0.3);
                border: 1px solid rgba(255, 255, 255, 0.2);
            }
            .breakdown-container span.operator {
                color: #BBDEFB;
                margin: 0 8px;
            }

            /* 2. æ‰‹æ©ŸéŸ¿æ‡‰å¼èª¿æ•´ */
            @media (max-width: 600px) {
                .breakdown-container {
                    font-size: 1.2rem !important;
                    display: block;
                    text-align: center;
                }
            }

            /* 3. å–®å­—èˆ‡éŸ³æ¨™ */
            .hero-word { font-size: 2.5rem; font-weight: 800; color: #333; }
            /* å¦‚æœåœ¨æ·±è‰²æ¨¡å¼ä¸‹ï¼Œå–®å­—æ¨™é¡Œä¹Ÿè¦ç¢ºä¿çœ‹å¾—åˆ° */
            @media (prefers-color-scheme: dark) {
                .hero-word { color: #FFF; }
            }
            .hero-phonetic { font-size: 1.2rem; color: #888; font-family: monospace; margin-bottom: 10px; }

            /* 4. [ä¿®æ­£é»] èªæ„Ÿå€å¡Šï¼šå¼·åˆ¶æ·±è‰²æ–‡å­— */
            .vibe-box { 
                background-color: #E3F2FD; 
                padding: 15px; 
                border-radius: 10px; 
                border-left: 5px solid #2196F3; 
                
                /* é€™è£¡å¼·åˆ¶æŒ‡å®šæ–‡å­—é¡è‰²ç‚ºæ·±ç°ï¼Œé¿å…è¢«æ·±è‰²æ¨¡å¼åç™½ */
                color: #333333 !important; 
            }
            /* ç¢ºä¿ box è£¡é¢çš„æ¨™é¡Œä¹Ÿæ˜¯æ·±è—è‰² */
            .vibe-box h4 {
                color: #1565C0 !important;
            }
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. å·¥å…·å‡½å¼
# ==========================================

def speak(text, key_suffix=""):
    try:
        if not text: return
        
        # --- [æ–°å¢] è‹±èªæ¿¾ç¶² ---
        # åªä¿ç•™ A-Z, a-z, 0-9, ç©ºæ ¼,é€£å­—è™Ÿ(-), æ’‡è™Ÿ(')
        # é€™æ¨£ "Quantum Mechanics (é‡å­åŠ›å­¸)" è®Šæˆ "Quantum Mechanics"
        # è€Œ "é»‘æ´" è®Šæˆ "" (ç©ºå­—ä¸²)ï¼Œå°±ä¸æœƒç™¼å‡ºæ€ªè²
        english_only = re.sub(r"[^a-zA-Z0-9\s\-\']", "", str(text)).strip()
        
        # å¦‚æœæ¿¾å®Œæ²’æ±è¥¿ï¼ˆä»£è¡¨å…¨æ˜¯ä¸­æ–‡ï¼‰ï¼Œå°±ç›´æ¥è·³å‡ºï¼Œä¸æ’­æ”¾
        if not english_only:
            return
            
        tts = gTTS(text=english_only, lang='en')
        fp = BytesIO()
        tts.write_to_fp(fp)
        audio_base64 = base64.b64encode(fp.getvalue()).decode()
        unique_id = f"audio_{int(time.time())}_{key_suffix}"
        st.components.v1.html(f'<audio id="{unique_id}" autoplay="true" style="display:none;"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio><script>document.getElementById("{unique_id}").play();</script>', height=0)
    except Exception as e: st.error(f"èªéŸ³éŒ¯èª¤: {e}")

def get_spreadsheet_url():
    """å®‰å…¨åœ°ç²å–è©¦ç®—è¡¨ç¶²å€ï¼Œç›¸å®¹å…©ç¨® secrets æ ¼å¼"""
    try:
        # å„ªå…ˆå˜—è©¦ connections çµæ§‹
        return st.secrets["connections"]["gsheets"]["spreadsheet"]
    except:
        try:
            # å‚™ç”¨ï¼šç›´æ¥çµæ§‹
            return st.secrets["gsheets"]["spreadsheet"]
        except:
            st.error("æ‰¾ä¸åˆ° spreadsheet è¨­å®šï¼Œè«‹æª¢æŸ¥ secrets.toml")
            return ""

@st.cache_data(ttl=60)
def load_db():
    COL_NAMES = [
        'category', 'roots', 'meaning', 'word', 'breakdown', 
        'definition', 'phonetic', 'example', 'translation', 'native_vibe',
        'synonym_nuance', 'visual_prompt', 'social_status', 'emotional_tone', 'street_usage',
        'collocation', 'etymon_story', 'usage_warning', 'memory_hook', 'audio_tag'
    ]
    
    # ä½¿ç”¨ GSheetsConnection è®€å– (æ¯” pd.read_csv æ›´ç©©å®šä¸”èƒ½åˆ©ç”¨å¿«å–)
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        url = get_spreadsheet_url()
        df = conn.read(spreadsheet=url, ttl=60) # åŠ å…¥ TTL é¿å…é »ç¹è®€å–
        
        # å¼·åˆ¶å°é½Š 20 æ¬„
        for col in COL_NAMES:
            if col not in df.columns:
                df[col] = ""
        
        # åªä¿ç•™é€™ 20 å€‹æ¬„ä½ä¸¦å»é™¤éå–®å­—è¡Œ
        df = df[COL_NAMES].dropna(subset=['word']).fillna("").reset_index(drop=True)
        return df
    except Exception as e:
        # Fallback: å¦‚æœé€£ç·šå¤±æ•—ï¼Œå›å‚³ç©ºè¡¨ä»¥å… App å´©æ½°
        st.error(f"è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        return pd.DataFrame(columns=COL_NAMES)

# ==========================================
# 3. AI è§£ç¢¼æ ¸å¿ƒ (è‡ªç”¨è§£é–ç‰ˆ)
# ==========================================
def ai_decode_and_save(input_text, fixed_category):
    """
    é€²åŒ–ç‰ˆè§£ç¢¼å‡½å¼ï¼š
    1. æ¥æ”¶ä½¿ç”¨è€…é¸å®šçš„å›ºå®šé ˜åŸŸ (fixed_category)ã€‚
    2. æ³¨å…¥å¼·åˆ¶æŒ‡ä»¤ï¼Œé–å®š AI çš„å°ˆæ¥­è¦–è§’ã€‚
    3. åŸ·è¡Œ JSON æå–èˆ‡å®‰å…¨éæ¿¾ã€‚
    """
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings)
    
    try:
        base_prompt = st.secrets["SYSTEM_PROMPT"]
    except KeyError:
        st.error("âŒ å¯†ç¢¼ç®±ä¸­æ‰¾ä¸åˆ° SYSTEM_PROMPT")
        return None
    
    # --- é—œéµä¿®æ­£ï¼šæ³¨å…¥é ˜åŸŸé–å®šæŒ‡ä»¤ ---
    lock_instruction = f"""
    ã€é ˜åŸŸé–å®šæŒ‡ä»¤ã€‘ï¼š
    1. ä½ ç›®å‰çš„èº«ä»½æ˜¯ã€Œ{fixed_category}ã€å°ˆå®¶ã€‚
    2. JSON ä¸­çš„ 'category' æ¬„ä½å¿…é ˆç²¾ç¢ºå¡«å¯«ç‚ºï¼šã€Œ{fixed_category}ã€ã€‚
    3. è«‹å‹™å¿…å¾ã€Œ{fixed_category}ã€çš„å°ˆæ¥­çŸ¥è­˜é«”ç³»å‡ºç™¼ï¼Œæä¾›æ·±åº¦çš„è§£æ§‹å…§å®¹ã€‚
    """
    
    final_prompt = f"{base_prompt}\n\n{lock_instruction}\n\nè§£ç¢¼ç›®æ¨™ï¼šã€Œ{input_text}ã€"
    
    try:
        response = model.generate_content(final_prompt)
        raw_text = response.text
        
        # æå– JSON éƒ¨åˆ†
        match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        if match:
            return match.group(0)
        return raw_text
            
    except Exception as e:
        st.error(f"AI ç”Ÿæˆå‡ºéŒ¯: {e}")
        return None
def show_encyclopedia_card(row):
    """ç¾åŒ–é¡¯ç¤ºå–®ä¸€å–®å­—çš„ç™¾ç§‘å¡ç‰‡"""
    st.markdown(f"<div class='hero-word'>{row['word']}</div>", unsafe_allow_html=True)
    st.markdown(f"<div class='hero-phonetic'>/{row['phonetic']}/</div>", unsafe_allow_html=True)
    
    col_a, col_b = st.columns([1, 4])
    with col_a:
        if st.button("ğŸ”Š æœ—è®€", key=f"spk_{row['word']}_{int(time.time())}", use_container_width=True):
            speak(row['word'], "card")
    with col_b:
        styled_breakdown = str(row['breakdown']).replace("+", "<span class='operator'>+</span>")
        st.markdown(f"<div class='breakdown-container'>{styled_breakdown}</div>", unsafe_allow_html=True)

    c1, c2 = st.columns(2)
    with c1:
        st.info(f"**ğŸ¯ å®šç¾©ï¼š**\n{row['definition']}")
        st.write(f"**ğŸ“ ä¾‹å¥ï¼š**\n{row['example']}")
        st.caption(f"ï¼ˆ{row['translation']}ï¼‰")
    with c2:
        st.success(f"**ğŸ’¡ å­—æ ¹ï¼š** {row['roots']}\n\n**æ„ç¾©ï¼š** {row['meaning']}")
        st.markdown(f"**ğŸª è¨˜æ†¶é‰¤å­ï¼š**\n{row['memory_hook']}")

    # èªæ„Ÿéƒ¨åˆ†
    if row['native_vibe']:
        st.markdown(f"""
            <div class='vibe-box'>
                <h4 style='color:#1E88E5; margin-top:0;'>ğŸŒŠ æ¯èªäººå£«èªæ„Ÿ (Native Vibe)</h4>
                <p style='font-size: 1.1rem;'>{row['native_vibe']}</p>
            </div>
        """, unsafe_allow_html=True)

    with st.expander("ğŸ“š æŸ¥çœ‹æ·±åº¦ç™¾ç§‘ (æ–‡åŒ–ã€ç¤¾æœƒã€è¡—é ­å¯¦æˆ°)"):
        t1, t2, t3 = st.tabs(["ğŸ›ï¸ å­—æºæ–‡åŒ–", "ğŸ‘” ç¤¾æœƒåœ°ä½", "ğŸ˜ è¡—é ­å¯¦æˆ°"])
        with t1:
            st.write(f"**ğŸ“œ å­—æºæ•…äº‹ï¼š** {row['etymon_story']}")
            st.write(f"**âš–ï¸ åŒç¾©è©è¾¨æï¼š** {row['synonym_nuance']}")
        with t2:
            st.write(f"**ğŸ¨ è¦–è¦ºæç¤ºï¼š** {row['visual_prompt']}")
            st.write(f"**ğŸ‘” ç¤¾æœƒæ„Ÿï¼š** {row['social_status']} | **ğŸŒ¡ï¸ æƒ…ç·’å€¼ï¼š** {row['emotional_tone']}")
        with t3:
            st.write(f"**ğŸ™ï¸ è¡—é ­ç”¨æ³•ï¼š** {row['street_usage']}")
            st.write(f"**ğŸ”— å¸¸ç”¨æ­é…ï¼š** {row['collocation']}")
            if row['usage_warning']:
                st.error(f"âš ï¸ ä½¿ç”¨è­¦å‘Šï¼š{row['usage_warning']}")

# ==========================================
# 4. é é¢é‚è¼¯
# ==========================================
def page_ai_lab():
    st.title("ğŸ”¬ Kadowsella è§£ç¢¼å¯¦é©—å®¤")
    
    # 1. å®šç¾©å›ºå®šé ˜åŸŸæ¸…å–®
    FIXED_CATEGORIES = [
        "è‹±èªè¾­æº", "èªè¨€é‚è¼¯", "ç‰©ç†ç§‘å­¸", "ç”Ÿç‰©é†«å­¸", "å¤©æ–‡åœ°è³ª", "æ•¸å­¸é‚è¼¯", 
        "æ­·å²æ–‡æ˜", "æ”¿æ²»æ³•å¾‹", "ç¤¾æœƒå¿ƒç†", "å“²å­¸å®—æ•™", "è»äº‹æˆ°ç•¥", "è€ƒå¤ç™¼ç¾",
        "å•†æ¥­å•†æˆ°", "é‡‘èæŠ•è³‡", "ç¨‹å¼é–‹ç™¼", "äººå·¥æ™ºæ…§", "ç”¢å“è¨­è¨ˆ", "æ•¸ä½è¡ŒéŠ·",
        "è—è¡“ç¾å­¸", "å½±è¦–æ–‡å­¸", "æ–™ç†é£Ÿè§€", "é‹å‹•å¥èº«", "æµè¡Œæ–‡åŒ–", "é›œé¡", "è‡ªå®šç¾©"
    ]
    
    col_input, col_cat = st.columns([2, 1])
    
    with col_input:
        new_word = st.text_input("è¼¸å…¥è§£ç¢¼ä¸»é¡Œï¼š", placeholder="ä¾‹å¦‚: 'Entropy'...")
        
    with col_cat:
        selected_category = st.selectbox("é¸å®šé ˜åŸŸæ¨™ç±¤", FIXED_CATEGORIES)
        
    # è™•ç†è‡ªå®šç¾©é ˜åŸŸé‚è¼¯
    if selected_category == "è‡ªå®šç¾©":
        custom_cat = st.text_input("è«‹è¼¸å…¥è‡ªå®šç¾©é ˜åŸŸåç¨±ï¼š")
        final_category = custom_cat if custom_cat else "æœªåˆ†é¡"
    else:
        final_category = selected_category

    force_refresh = st.checkbox("ğŸ”„ å¼·åˆ¶åˆ·æ–° (è¦†è“‹èˆŠè³‡æ–™)")
    
    if st.button("å•Ÿå‹•ä¸‰ä½ä¸€é«”è§£ç¢¼", type="primary"):
        if not new_word:
            st.warning("è«‹å…ˆè¼¸å…¥å…§å®¹ã€‚")
            return

        # --- æ­¥é©Ÿ 1: æª¢æŸ¥è³‡æ–™åº« ---
        conn = st.connection("gsheets", type=GSheetsConnection)
        url = get_spreadsheet_url()
        existing_data = conn.read(spreadsheet=url, ttl=0)
        
        is_exist = False
        if not existing_data.empty:
            match_mask = existing_data['word'].astype(str).str.lower() == new_word.lower()
            is_exist = match_mask.any()

        if is_exist and not force_refresh:
            st.warning(f"âš ï¸ ã€Œ{new_word}ã€å·²åœ¨æ›¸æ¶ä¸Šï¼")
            existing_row = existing_data[match_mask].iloc[0].to_dict()
            st.markdown("---")
            show_encyclopedia_card(existing_row)
            return

        # --- æ­¥é©Ÿ 2: AI ç”Ÿæˆ (é—œéµä¿®æ­£ï¼šå‚³å…¥ final_category) ---
        with st.spinner(f'æ­£åœ¨ä»¥ã€{final_category}ã€‘å°ˆæ¥­è¦–è§’è§£ç¢¼ã€Œ{new_word}ã€...'):
            try:
                # é€™è£¡å‘¼å«æˆ‘å€‘å„ªåŒ–éçš„å‡½å¼
                raw_res = ai_decode_and_save(new_word, final_category)
                
                match = re.search(r'\{.*\}', raw_res, re.DOTALL)
                if not match:
                    st.error("AI è¼¸å‡ºè§£æå¤±æ•—ã€‚")
                    return
                
                res_data = json.loads(match.group(0))

                # --- æ­¥é©Ÿ 3: è³‡æ–™è¦†å¯«èˆ‡å­˜æª” ---
                if is_exist and force_refresh:
                    existing_data = existing_data[~match_mask]
                    st.toast(f"ğŸ—‘ï¸ å·²æ›¿æ›èˆŠç‰ˆæ•¸æ“š", icon="ğŸ”„")

                new_row = pd.DataFrame([res_data])
                updated_df = pd.concat([existing_data, new_row], ignore_index=True)
                
                conn.update(spreadsheet=url, data=updated_df)
                
                st.success(f"ğŸ‰ ã€Œ{new_word}ã€è§£ç¢¼æˆåŠŸï¼")
                st.balloons()
                st.markdown("---")
                show_encyclopedia_card(res_data)

            except Exception as e:
                st.error(f"è§£ç¢¼éç¨‹å‡ºéŒ¯: {e}")
def page_home(df):
    st.markdown("<h1 style='text-align: center;'>Etymon Decoder</h1>", unsafe_allow_html=True)
    st.write("---")
    
    # 1. æ•¸æ“šå„€è¡¨æ¿
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ“š ç¸½å–®å­—é‡", len(df))
    c2.metric("ğŸ·ï¸ åˆ†é¡ä¸»é¡Œ", df['category'].nunique() if not df.empty else 0)
    c3.metric("ğŸ§© ç¨ç‰¹å­—æ ¹", df['roots'].nunique() if not df.empty else 0)
    
    st.write("---")

    # 2. [æ–°å¢] éš¨æ©Ÿæ¨è–¦å±•ç¤ºå€
    st.subheader("ğŸ’¡ ä»Šæ—¥éš¨æ©Ÿæ¨è–¦")
    
    if not df.empty:
        # å¦‚æœè³‡æ–™åº«å°‘æ–¼ 3 ç­†ï¼Œå°±å…¨ç§€ï¼›å¦å‰‡éš¨æ©ŸæŠ½ 3 ç­†
        sample_count = min(3, len(df))
        #æ¯æ¬¡é‡æ–°æ•´ç†é é¢éƒ½æœƒè®Šå‹•
        sample = df.sample(sample_count) 
        
        # ä½¿ç”¨ 3 å€‹æ¬„ä½ä¸¦æ’é¡¯ç¤ºï¼Œçœ‹èµ·ä¾†æ›´åƒå¡ç‰‡
        cols = st.columns(3)
        for i, (index, row) in enumerate(sample.iterrows()):
            with cols[i % 3]: # ç¢ºä¿åœ¨ 3 æ¬„å…§å¾ªç’°
                with st.container(border=True): # åŠ å€‹é‚Šæ¡†æ›´æœ‰è³ªæ„Ÿ
                    st.markdown(f"### {row['word']}")
                    st.caption(f"ğŸ·ï¸ {row['category']}")
                    st.write(f"**å®šç¾©ï¼š** {row['definition']}")
                    st.write(f"**æ ¸å¿ƒï¼š** {row['roots']}")
                    # é€™è£¡å¯ä»¥åŠ ä¸€å€‹å°æŒ‰éˆ•ï¼Œé»äº†æœ—è®€è©²å–®å­—
                    if st.button("ğŸ”Š", key=f"home_spk_{row['word']}"):
                        speak(row['word'], "home")
    else:
        st.info("ğŸ‘ˆ è³‡æ–™åº«ç›®å‰æ˜¯ç©ºçš„ï¼Œè«‹å¾å·¦å´é€²å…¥ã€Œè§£ç¢¼å¯¦é©—å®¤ã€æ–°å¢ç¬¬ä¸€ç­†çŸ¥è­˜ï¼")

    st.write("---")
    st.info("ğŸ‘ˆ é»æ“Šå·¦å´é¸å–®é€²å…¥ã€Œå­¸ç¿’èˆ‡æœå°‹ã€æŸ¥çœ‹å®Œæ•´è³‡æ–™åº«ã€‚")

def page_learn_search(df):
    st.title("ğŸ“– å­¸ç¿’èˆ‡æœå°‹")
    if df.empty:
        st.warning("ç›®å‰æ›¸æ¶æ˜¯ç©ºçš„ã€‚")
        return

    tab_card, tab_list = st.tabs(["ğŸ² éš¨æ©Ÿæ¢ç´¢", "ğŸ” è³‡æ–™åº«åˆ—è¡¨"])
    
    with tab_card:
        cats = ["å…¨éƒ¨"] + sorted(df['category'].unique().tolist())
        sel_cat = st.selectbox("é¸æ“‡å­¸ç¿’åˆ†é¡", cats)
        f_df = df if sel_cat == "å…¨éƒ¨" else df[df['category'] == sel_cat]

        if st.button("ä¸‹ä¸€å€‹å–®å­— (Next Word) â”", use_container_width=True, type="primary"):
            st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()
            st.rerun()

        if 'curr_w' not in st.session_state and not f_df.empty:
            st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()

        if 'curr_w' in st.session_state:
            show_encyclopedia_card(st.session_state.curr_w)

    with tab_list:
        search = st.text_input("ğŸ” æœå°‹æ›¸æ¶å…§å®¹...")
        if search:
            mask = df.astype(str).apply(lambda x: x.str.contains(search, case=False)).any(axis=1)
            display_df = df[mask]
        else:
            display_df = df.head(50)
        st.dataframe(display_df[['word', 'definition', 'roots', 'category', 'native_vibe']], use_container_width=True)

def page_quiz(df):
    st.title("ğŸ§  å­—æ ¹è¨˜æ†¶æŒ‘æˆ°")
    if df.empty: return
    
    cat = st.selectbox("é¸æ“‡æ¸¬é©—ç¯„åœ", df['category'].unique())
    pool = df[df['category'] == cat]
    
    if st.button("ğŸ² æŠ½ä¸€é¡Œ", use_container_width=True):
        st.session_state.q = pool.sample(1).iloc[0].to_dict()
        st.session_state.show_ans = False

    if 'q' in st.session_state:
        st.markdown(f"### â“ è«‹å•é€™å°æ‡‰å“ªå€‹å–®å­—ï¼Ÿ")
        st.info(st.session_state.q['definition'])
        st.write(f"**æç¤º (å­—æ ¹):** {st.session_state.q['roots']} ({st.session_state.q['meaning']})")
        
        if st.button("æ­æ›‰ç­”æ¡ˆ"):
            st.session_state.show_ans = True
        
        if st.session_state.show_ans:
            st.success(f"ğŸ’¡ ç­”æ¡ˆæ˜¯ï¼š**{st.session_state.q['word']}**")
            speak(st.session_state.q['word'], "quiz")
            st.write(f"çµæ§‹æ‹†è§£ï¼š`{st.session_state.q['breakdown']}`")

# ==========================================
# 5. ä¸»ç¨‹å¼å…¥å£
# ==========================================
def main():
    inject_custom_css()
    
    st.sidebar.title("Kadowsella")
    
    # --- [è´ŠåŠ©å€å¡Š] é›™åˆ€æµ ---
    st.sidebar.markdown("""
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 12px; border: 1px solid #e9ecef; margin-bottom: 25px;">
            <p style="text-align: center; margin-bottom: 12px; font-weight: bold; color: #444;">ğŸ’– æ”¯æŒé–‹ç™¼è€…</p>
            <a href="https://www.buymeacoffee.com/kadowsella" target="_blank" style="text-decoration: none;">
                <div style="background-color: #FFDD00; color: #000; padding: 8px; border-radius: 8px; text-align: center; font-weight: bold; margin-bottom: 8px; font-size: 0.9rem;">
                    â˜• Buy Me a Coffee
                </div>
            </a>
            <a href="https://p.ecpay.com.tw/kadowsella20" target="_blank" style="text-decoration: none;">
                <div style="background: linear-gradient(90deg, #28C76F 0%, #81FBB8 100%); color: white; padding: 8px; border-radius: 8px; text-align: center; font-weight: bold; font-size: 0.9rem;">
                    è´ŠåŠ©ä¸€ç¢—ç±³ç³•ï¼
                </div>
            </a>
        </div>
    """, unsafe_allow_html=True)
    
    # --- [ç®¡ç†å“¡ç™»å…¥] ---
    is_admin = False
    with st.sidebar.expander("ğŸ” ç®¡ç†å“¡ç™»å…¥", expanded=False):
        input_pass = st.text_input("è¼¸å…¥å¯†ç¢¼", type="password")
        if input_pass == st.secrets.get("ADMIN_PASSWORD", "0000"):
            is_admin = True
            st.success("ğŸ”“ ä¸Šå¸æ¨¡å¼å•Ÿå‹•")

    # --- [é¸å–®é‚è¼¯] ---
    if is_admin:
        menu_options = ["é¦–é ", "å­¸ç¿’èˆ‡æœå°‹", "æ¸¬é©—æ¨¡å¼", "ğŸ”¬ è§£ç¢¼å¯¦é©—å®¤"]
        if st.sidebar.button("ğŸ”„ å¼·åˆ¶åŒæ­¥é›²ç«¯", help="æ¸…é™¤ App å¿«å–"):
            st.cache_data.clear()
            st.rerun()
    else:
        menu_options = ["é¦–é ", "å­¸ç¿’èˆ‡æœå°‹", "æ¸¬é©—æ¨¡å¼"]
    
    page = st.sidebar.radio("åŠŸèƒ½é¸å–®", menu_options)
    st.sidebar.markdown("---")
    
    df = load_db()
    
    if page == "é¦–é ":
        page_home(df)
    elif page == "å­¸ç¿’èˆ‡æœå°‹":
        page_learn_search(df)
    elif page == "æ¸¬é©—æ¨¡å¼":
        page_quiz(df)
    elif page == "ğŸ”¬ è§£ç¢¼å¯¦é©—å®¤":
        if is_admin:
            page_ai_lab()
        else:
            st.error("â›” è«‹å…ˆç™»å…¥")

    status = "ğŸ”´ ç®¡ç†å“¡" if is_admin else "ğŸŸ¢ è¨ªå®¢"
    st.sidebar.caption(f"v3.0 Ultimate | {status}")

if __name__ == "__main__":
    main()
